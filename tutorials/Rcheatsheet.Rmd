---
title: "R Cheat Sheet"
author: "Adele"
date: "2023-11-03"
output:
  html_document:
    theme: cerulean
    toc: yes
    toc_float:
      collapsed: yes
  pdf_document:
    toc: yes
---
# 1. 前期准备

### 如何装包
（eg: "install.packages("dplfy")"）

### library() 加载需要的包
```{r}
library(openxlsx)
library(dplyr)
library(ggplot2)
library(tidyr)
```

### 选择工作路径

更方便一点直接在右侧进入工作路径点击小齿轮设为工作路径
setwd("/path/to/my/directory")

### 数据读入
（csv 数据读入：read.csv("")）
```{r}
wb <- loadWorkbook("test_file.xlsx")
s1 = read.xlsx(wb, sheet = 1)
s2 = read.xlsx(wb, sheet = 2)
```

# 2. 查看数据
```{r}
head(s1)
```

### 查看数据结构：包括几个variable和数据类型
```{r}
str(s1)
```
### 每一个variable的摘要：
包括min, Q12(25%的数据小于或者等于这个数值), median/Q2, mean, Q3, max
```{r}
summary(s1)
```

### 检查行数 number of rows
```{r}
nrow(s1)
nrow(s2)
```
### 检查列数 number of columns
```{r}
ncol(s1)
ncol(s2)
```

### 检查有几个na数值
```{r}
#is.na() 返回一个完成只有true, false的数据表，是na项则为true，否则是false
na_count = sum(is.na(s1))
na_count
```

### 去掉所有带有na的行，如果不想覆盖原数据就保存一个新的dataframe
```{r}
s1 = na.omit(s1)
```

### 将指定列有na值替换成 0

```{r}
s2$Asylum.seekers.Incoming = replace(s2$Asylum.seekers.Incoming, is.na(s2$Asylum.seekers.Incoming), 0)
```

### 像指定列na值替换成 median

```{r}
s2$Number.of.Applications.Incoming[is.na(s2$Number.of.Applications.Incoming)] <- median(s2$Number.of.Applications.Incoming, na.rm = TRUE)
```

### 确定outlier

通常使用计算四分位距离（Interquartile Range/IQR）, outlier被定义为那些低于第一分位数\( Q1 \)减去1.5倍IQR的值，或者高于第三分位数\( Q3 \)加上1.5倍IQR的值。

```{r}

q1 = quantile(s2$Asylum.seekers.Incoming, 0.25)
q3 = quantile(s2$Asylum.seekers.Incoming, 0.75)
iqr = q3 - q1

#定义outlier界限
lower_bound = q1 - 1.5 * iqr
upper_bound = q3 + 1.5 * iqr

#检查outlier，'|' 是 or 的意思，‘&’ 是 and 的意思
outlier = s2$Asylum.seekers.Incoming[s2$Asylum.seekers.Incoming < lower_bound | s2$Asylum.seekers.Incoming > upper_bound]

print(outlier)
```
### 在表中新增一列为其他列之和 
和计算器一样其他之差，之积修改符号即可）如果$后选择已有列，会直接覆盖原数据
```{r}
s1$sum = s1$type_of_violence + s1$active_year
```

### 随便生成一个数据
```{r}
df <- data.frame(col1 = c(1, 1, 2, 2), col2 = c("A", "A", "B", "B"), col3 = c(100, 100, 200, 300))
df
```

### 将字符列转换为factor：
```{r}
df$col2 = as.factor(df$col2)
```

### 查看某一列数据类型

```{r}
str(df$col2)
```

### 返回唯一值
unique() 函数
用于从向量、数据框或其他对象中移除重复元素，只返回唯一值。
对于数据框，unique() 函数会返回所有不重复的行。
```{r}
unique_df <- unique(df)
unique_df
```

### 计算给定列中唯一值的个数

count() 函数通常在 dplyr 包中使用，用于快速计算给定列中唯一值的个数。

```{r}
count_df <- df %>%
  count(col2)
count_df
```

### 保存文件
保存成excel文件, write.csv() 则保存csv文件
```{r}
write.xlsx(s1, file = "result.xlsx", rowNames = FALSE)
```

# 3. 进阶处理

### 选择特定列成为新数据

```{r}
subset = s2[c("id","Year")]
head(subset)
```

### 根据第几列重命名
```{r}
colnames(subset)[2] <- "year"
head(subset)
```

### 根据指定列排序

如果多列，只需要在order后面加入条件即可

```{r}
id_sorted <- subset[order(subset$id), ]
head(id_sorted)
```

### 查找重复行数量

```{r}
duplicated_sums <- sum(duplicated(subset))
duplicated_sums
```

### 移除重复行
```{r}
subset <- subset[!duplicated(subset), ]
```

### 根据指定列数值进行subset

```{r}
subset2020 = subset[subset$year == "2020", ]
head(subset2020)
```

### 表格合并

```{r}
df1 <- data.frame(Key = c("A", "B", "C"), Value = 1:3)
df2 <- data.frame(Key = c("B", "C", "D"), Value = 4:6)
df1
df2
```
### 使用 rbind() 合并数据
rbind() 函数用于按行（row-wise）合并两个或多个数据框或矩阵，它们必须有相同数量的列，并且相应的列需要具有相同的数据类型
```{r}
combined_df <- rbind(df1, df2)
combined_df
```

### 使用 dplyr 包实现 join 操作 

### 内连接（Inner join）
通过variable "Key" 内连接（Inner join）返回两个数据框中匹配键的交集。

```{r}
inner_joined <- inner_join(df1, df2, by = "Key")
inner_joined
```
### 左连接 left join
通过variable "Key" 左连接 left join 返回第一个数据框的所有行，并与第二个数据框中的匹配行相连接。
```{r}
left_joined <- left_join(df1, df2, by = "Key")
left_joined
```

### 右连接 right join
通过variable "Key" 右连接 right join 返回第二个数据框的所有行，并与第一个数据框中的匹配行相连接。

```{r}
right_joined <- right_join(df1, df2, by = "Key")
right_joined
```
### 外连接（Full join）
返回两个数据框中所有匹配的行
```{r}
full_joined <- full_join(df1, df2, by = "Key")
full_joined
```


# 再进阶一些

### 使用`mutate()`和`filter()`进行数据转换
```{r}
## 创建 dataframe
df <- data.frame(col1 = c(1, 1, 2, 2), col2 = c("A", "A", "B", "B"), col3 = c(100, 100, 200, 300))

df <- df %>%
  mutate(new_column = col3 / col1) %>%
  filter(col1 > 0)
df
```

每一行代码的功能如下：

2. `data <- data %>% ...`: `%>%`是管道操作符，它会将左边的结果作为右边函数的第一个参数传递。在这个上下文中，它的意思是“拿`data`数据框然后应用以下函数”。

3. `mutate(new_column = column3 / column1)`: `mutate()`函数用于添加新列或改变现有列。这里，它创建了一个名为`new_column`的新列，该列的值是`column1`除以`column2`的结果。

4. `filter(column1 > 0)`: 创建新列后，使用`filter()`来保留`column1`大于0的行。

执行这一系列命令后，`data`将会新增一个列，并且只包含`column1`为正数的行。

### 使用`group_by()`和`summarise()`进行数据分组和汇总

```{r}
summary_data <- df %>%
  group_by(col2) %>%
  summarise(mean_value = mean(col3, na.rm = TRUE))
summary_data
```

2. `summary_data <- data %>% ...`: 这是另一个应用于`data`的`dplyr`函数链，并将结果存储在`summary_data`中。

3. `group_by(group_column)`: `group_by()`函数用于根据`column2`的唯一值在数据中创建分组。之后的所有操作都是在这些分组内部进行，而不是在整个数据集上进行。

4. `summarise(mean_value = mean(col3, na.rm = TRUE))`: 分组后，使用`summarise()`函数将每个组合并成一个单一的汇总行。在这个案例中，它为每个组计算`col3`的平均值。参数`na.rm = TRUE`告诉平均数函数忽略`NA`（缺失）值。

`summary_data`将包含每个唯一`col2`值的`col3`的平均值。



## 高阶函数 apply（）

用来应用某个函数于数据框或矩阵边缘的高阶函数。基本上，你可以用它来对行或列执行一个函数。apply() 函数的一般形式如下：apply(X, MARGIN, FUN, ...)

X 是输入的数组，数据框（data frame）或矩阵（matrix）
MARGIN 是一个整数，指定你想要应用函数的维度。1 表示行，2 表示列。
FUN 是要应用的函数


```{r}
df <- data.frame(a = c(1, 3, 5), b = c(2, 4, 6))
df
```
### 找出每一行最大值
```{r}
apply(df, 1, max)
```

### 创建一个矩阵，计算每列的和
```{r}
# 创建一个矩阵
mat <- matrix(1:9, nrow = 3)
mat
# 计算每列的和
apply(mat, 2, sum)
```

### 对数据框的列应用自定义函数，自定义函数部分之后再说
```{r}
# 创建一个数据框
df <- data.frame(a = c(1, 3, 5), b = c(2, 4, 6))

# 定义一个自定义函数
custom_function <- function(x) {
  return(mean(x) + sd(x))
}

# 应用自定义函数至每列
apply(df, 2, custom_function)

```

## 创造一个数据框
```{r}
df = tibble::tribble(
  ~id, ~income_2019, ~income_2020, ~income_2021,
  1,        50000,        52000,        55000,
  2,        48000,        50000,        53000
)
df
```

## 把宽表格转成长表格

```{r}
df_long = pivot_longer(
  df,
  cols = starts_with("income"),
  names_to = "year",
  names_prefix = "income_",
  values_to = "income"
)
df_long
```

转换后的 `people_long` 会有三列：`id`, `year`, 和 `income`，其中原始的 `income_2019`, `income_2020`, `income_2021` 列名会变成 `year` 列中的值，而相应的收入数值会被放到 `income` 列中。

### pivot_longer() 小课堂

`pivot_longer()` 是 `tidyr` 包中的一个函数，用于将宽格式数据转换为长格式数据。这通常在你有多列代表相同类型的信息时非常有用，比如多个时间点的观测值分散在不同的列中。长格式通常更适合于分析工作，因为它将数据组织成一个可以通过分组变量进行聚合的形式。

下面是 `pivot_longer()` 函数参数的解释：

- `data`: 你想要转换的数据框（data frame）或者 tibble。
- `cols`: 选择要变长的列。你可以使用dplyr选择助手如 `starts_with()`, `ends_with()`, `contains()`, `matches()`, `num_range()` 等，或者使用 `!` 来排除列。
- `...`: 其他选择列的参数。
- `cols_vary`: 对于选择多个列，是否应该在变换中保持列的顺序不变（`"slowest"`）还是允许改变以提高速度（`"fastest"`）。
- `names_to`: 长格式数据中新列的名称，用于保存原始列的名称。可以是一个字符向量，如果你想要从列名中分离出多个变量。
- `names_prefix`: 一个字符向量，用来删除从原始列名开始的共同前缀。
- `names_sep`: 当`names_to`包含多个名称时，这个参数定义了列名中用来分隔变量的字符或正则表达式。
- `names_pattern`: 一个正则表达式，用来通过捕获组从列名中提取多个变量。只有当`names_to`包含多个变量时，这个参数才有用。
- `names_ptypes`: 一个列表，指定了由`names_to`生成的新列的类型。默认情况下，列的类型会从数据自动推断出来。
- `names_transform`: 一个列表，用函数来转换由`names_to`生成的新列的值。
- `names_repair`: 用于处理新列名的函数，`"check_unique"` 是默认值，它会检查新列名是否唯一。
- `values_to`: 新列的名称，用于存储`cols`中的值。
- `values_drop_na`: 是否应该删除那些在`values_to`中为`NA`的行，默认为`FALSE`。
- `values_ptypes`: 一个列表，指定了由`values_to`生成的新列的类型。
- `values_transform`: 一个列表，用函数来转换由`values_to`生成的新列的值。


## 把长表格转为宽表壳
```{r}
wide = pivot_wider(
        df_long, 
        names_from = year, 
        names_glue = "{year}_income",
        values_from = income)
wide
```
### pivot_wider小课堂

`pivot_wider()` 是 `tidyr` 包中的一个函数，用于将数据从“长格式”转换为“宽格式”。在“长格式”数据中，关键值通常被存储在列中，这些列包含了许多观测结果，而在“宽格式”数据中，每个观测结果通常有其自己的列。`pivot_wider()` 函数的参数允许你自定义这个转换过程。以下是这些参数的解释：

- `data`: 你想要转换的数据框或者 tibble。

- `...`: 一些用来选择列的附加参数，例如 `dplyr` 的选择助手函数。

- `id_cols`: 用于保持为唯一标识符的列，即那些在转宽格式时不会变动的列。

- `id_expand`: 如果设置为 TRUE，将会创建所有唯一值的组合，即使这些组合在原始数据中并不存在。

- `names_from`: 需要从长格式的值转换为宽格式列名的列。

- `names_prefix`: 在新列名之前加上的前缀字符串。

- `names_sep`: 当从多个列创建新列名时，用于分隔这些名字的字符。

- `names_glue`: 一个 `glue` 语法的字符串，用于精确地描述如何结合 `names_from` 中的值来创建新列名。在我们的例子中，`names_glue` 参数指定了新列名应该如何被构造。`{year}` 是一个占位符，它将被 `names_from` 参数指定的 `year` 列的值所替换。这样，如果 `year` 列包含了 2020 和 2021，转换后的宽格式数据框将会有 `2020_income` 和 `2021_income` 这样的列名。

- `names_sort`: 如果为 TRUE，将根据 `names_from` 的值对新列进行排序。

- `names_vary`: 控制当 `names_from` 有多个值时，列名的变化速度。默认值是 "fastest"。

- `names_expand`: 如果为 TRUE，将使用 `names_from` 和 `values_from` 列的所有唯一值组合来创建列，即使某些组合在输入数据中并不存在。

- `names_repair`: 指定如何处理不规则的列名，"check_unique" 是默认值，它会检查列名是否唯一，并在需要时修复。

- `values_from`: 要扩展到宽格式列值的列。

- `values_fill`: 当转换为宽格式时，对于不存在的组合可以使用的填充值。

- `values_fn`: 一个函数或函数的列表，用于对聚合的值进行处理，如果在转换过程中一个单元格对应多个值。

- `unused_fn`: 用于处理 `names_from` 和 `values_from` 中未使用的组合的函数。


# 基础绘图 visualization

### 随便生成一组数据用来分析
```{r}
set.seed(123) # 确保可复现性

# 生成三个组的数据，每组30个观察值
groupA <- rnorm(30, mean = 50, sd = 10)
groupB <- rnorm(30, mean = 55, sd = 10)
groupC <- rnorm(30, mean = 45, sd = 10)

# 将数据组合成一个数据框，这对绘图和分析都有用
data <- data.frame(
  value = c(groupA, groupB, groupC),
  group = factor(rep(c("A", "B", "C"), each = 30))
)
head(data)
```

### boxplot
用于判断数据分布区间, 用来看outlier
```{r}
boxplot(value ~ group, 
        data = data, 
        main = "Boxplot of Groups", 
        ylab = "value", 
        xlab = "group")

```

### 柱状图histogram
用来看单个数据分布
```{r}
hist(data$value, 
     breaks = 10, 
     main = "Histogram of Values", 
     xlab = "Value")

```
### 饼状图
显示的是每个组占总体的比例
```{r}
pie(table(data$group), 
    main = "Pie Chart of Groups")
```

### 折线图（Line Chart）
折线图显示数据随时间或顺序变化的趋势，使用groupA的数据按照值排序来模拟。

```{r}
# 对数据框中每个组内的值进行排序
data_sorted <- data %>%
  group_by(group) %>%
  mutate(rank = rank(value)) %>%
  ungroup()
data_sorted
```

## ggplot2绘图
rank()函数用于为每个组内的value创建排名，然后基于这个排名进行绘图。
这样每个组的线都会基于组内的值排序，而不是整个数据集的排序。

```{r}
# 使用ggplot2绘图
ggplot(data_sorted, aes(x = rank, y = value, group = group, color = group)) + 
  geom_line() +
  labs(title = "Line Chart of Sorted Group Values", x = "Rank", y = "Value") +
  theme_minimal()
```
# 统计学术语

简单来说，只要 p<0.05， 我们就可以说，这个结论不是随即发生的，是受到一定因素影响的

## 统计学显著 statitical significant
统计学显著性是一个衡量结果不太可能是偶然发生的标准。在统计假设检验中，我们通常设置一个阈值（显著性水平），如0.05或5%，来决定一个统计结果是否显著。如果得到的p值小于这个阈值，我们就说结果在统计上是显著的。

以下是一些与统计学显著性相关的关键点：

### 假设检验
- **Null Hypothesis (H0)**: 一个基准假设，通常是表明没有效果或差异的假设，如两个样本的均值之间没有差异。
- **Alternative Hypothesis (H1)**: 这是与零假设对立的假设，即存在某种效果或差异。

### P值
- **P值**: 给出了在零假设为真的情况下，观察到的数据或更极端数据出现的概率。一个低的p值（通常小于0.05）表明在零假设下这样的数据是不太可能的，因此我们拒绝零假设。

### 显著性水平（α）
- **显著性水平**: 是在实验之前选择的一个阈值，它定义了拒绝零假设的标准。如果p值小于显著性水平（例如，α=0.05），我们认为结果在统计上显著。

### 类型 I 和 类型 II 错误
- **类型 I 错误（错误的拒绝真正的零假设）**: 当零假设实际上是真的时我们却拒绝了它，犯了类型 I 错误。显著性水平就是犯这种错误的概率。
- **类型 II 错误（错误地接受了一个假的零假设）**: 当零假设是假的但是我们没有拒绝它时，我们犯了类型 II 错误。这个错误的概率用β表示。

### 统计力量
- **统计力量**: 是正确拒绝错误零假设的能力，即发现实际存在的效果的能力。统计力量与样本大小、效应量和显著性水平有关。

总结一下，统计学显著性是我们用来确定观察到的数据模式是否不太可能仅仅是随机变异的一种方法。通过设定显著性水平，并计算得到的统计量的p值，我们能够决定是否拒绝零假设。如果拒绝了零假设，我们通常会声称发现了统计学上显著的效果。这是一种通过数据来支持或反对某个科学假设的方法。

## 置信区间

置信区间是一个来自于统计学的概念，它提供了对未知参数（比如平均数、比例、差异等）可能值的一个区间估计。在实际应用中，这个区间表示了，在一定的置信水平（常见的如95%）下，参数的真实值有很大概率落在这个区间内。这是基于抽样分布和概率的概念，意味着如果我们重复抽样和计算置信区间很多次，那么有95%的这些区间将包含真实的参数值。

当我们在Tukey的多重比较结果中看到一个置信区间时，它代表了：

- `lwr`：置信区间的下限（Lower bound）
- `upr`：置信区间的上限（Upper bound）

如果置信区间的两个边界值`lwr`和`upr`都是正数，或者都是负数，那么我们可以说这个置信区间不包括0，这通常意味着差异是统计学上显著的。相反，如果置信区间从负数跨越到正数（即`lwr`是负的，`upr`是正的），这个区间就包含了0，通常表明差异不是统计学上显著的。

例如，假设一个置信区间是(-1.79, 1.08)：

- 这个置信区间的下限是-1.79，上限是1.08。
- 因为这个区间包括了从负数到正数的值，所以它包含了0。
- 这表示我们不能拒绝两组之间没有差异的假设。

在实际应用中，置信区间的宽度也提供了一定的信息，更宽的置信区间意味着更大的不确定性。置信区间的宽度受样本大小、变异性以及置信水平的影响。更大的样本、更低的变异性或更低的置信水平（如90%）通常会导致更窄的置信区间，表示估计更精确。


# ANOVA 统计分析

我们将假设我们正在研究三种不同种类的细胞在不同试剂处理下的生长效果。目标是判断试剂类型是否对细胞生长有显著影响。

## **第一步：收集数据**

首先，你会收集数据。比如你有三种细胞（A、B、C），并且有两种试剂类型（X和Y）。你测量了使用不同试剂后细胞的生长速度。数据可能是这样收集的：

- Cell A with Reagents X
- Cell A with Reagents Y
- Cell B with Reagents X
- Cell B with Reagents Y
- Cell C with Reagents X
- Cell C with Reagents Y

每个组合收集30个数据点。

## **第二步：整理数据**

将数据整理成一个`data.frame`对象，例如:

```{r}
# 假设的数据
set.seed(123) # 确保结果的可重复性
cell_growth <- data.frame(
  cell_type = factor(rep(c("A", "B", "C"), each = 60)),
  reagents_type = factor(rep(c("X", "Y"), each = 30)),
  days = c(rnorm(30, mean = 35, sd = 3.5), 
             rnorm(30, mean = 40, sd = 3.5), 
             rnorm(30, mean = 30, sd = 3.5), 
             rnorm(30, mean = 45, sd = 3.5), 
             rnorm(30, mean = 25, sd = 3.5), 
             rnorm(30, mean = 50, sd = 3.5))
)
head(cell_growth)
```


## **第三步：进行ANOVA分析**

我们使用ANOVA来看看试剂类型是否显著影响细胞生长速度。

```{r}
# ANOVA
aov_result <- aov(days ~ cell_type * reagents_type, data = cell_growth)
summary(aov_result)
```

### 如何分析这个模型结果：

想象你是一位生物学家，正在研究不同类型的细胞（`cell_type`）和不同试剂（`reagents_type`）对细胞生长天数的影响。你设计了一个实验来评估：

1. 不同细胞类型是否影响细胞生长天数。
2. 不同试剂是否影响细胞生长天数。
3. 细胞类型和试剂是否相互作用影响细胞生长天数。

你的实验结果包括以下几个方面：

- **Df（自由度）**：这是指你在分析数据时自由选择数据点的能力。例如，如果你有三种细胞类型，自由度就是2（一旦你知道了两种细胞的生长情况，第三种就不再自由）。自由度。它是指在计算某个统计量时，能够自由变动的值的个数。这里，cell_type有2个自由度（通常是类别数减1），reagents_type有1个自由度，它们的交互作用 cell_type:reagents_type有2个自由度，最后Residuals（残差，也就是无法由模型解释的变异）有174个自由度。

- **Sum Sq（总平方和）**：这是所有数据点偏离整体平均值的平方和，它衡量的是因变量（这里是细胞生长天数）的总变异量。在你的实验中，总平方和越大，表示变异越大，相应因素的影响可能就越显著。它表示由该因子引起的变异量总和。在这里，cell_type引起的变异很小，只有4，而reagents_type引起的变异非常大，为10837。

- **Mean Sq（均方）**：这是总平方和除以相应的自由度得到的，它代表了每个因素引起的平均变异大小。它是和平方和除以对应的自由度，反映了每个因子每个自由度上的平均变异量。比如reagents_type的均方是10837，这意味着每一个reagents_type类别带来的平均变异量是10837。

- **F value**：这是用来比较模型中的均方与残差均方的比率。如果这个比率足够大，说明模型中的对应因素有统计学意义。F值是均方之间的比率。它用于检验我们的组间是否有显著差异。在这里，reagents_type的F值是974.933，而cell_type:reagents_type的交互作用的F值是141.159，这两个都相对较高，表明它们各自和共同都对结果有显著影响。

- **Pr(>F)（P值）**：这是你观测到的F值或更极端情况出现的概率。一个低P值（通常小于0.05）表明结果具有统计学意义，即非随机差异的可能性很高。这个是P值，用来告诉我们观察到的数据在没有任何效应的情况下（即零假设），出现的概率。如果这个值很小，它表明这种情况出现的可能性很低，我们就可以拒绝零假设。在这个输出中，reagents_type和cell_type:reagents_type的P值都远远小于0.001（标记为***），这表示它们的影响是非常显著的。而cell_type的P值为0.83，表明它并没有显著影响

### 根据你的实验结果：

- `cell_type`的P值为0.83，表明不同的细胞类型对细胞生长天数的影响不显著，细胞类型的变化并不会导致生长天数的显著变化。

- `reagents_type`的P值非常低（<0.001），这意味着不同的试剂显著影响了细胞的生长天数。换句话说，试剂的种类是一个影响细胞生长天数的重要因素。

- `cell_type`和`reagents_type`的交互作用也有非常低的P值（<0.001），表示细胞类型和试剂的组合对细胞生长天数有显著的联合影响。也就是说，某些试剂可能对某些细胞类型的生长影响特别大。

综上所述，你的实验表明，尽管不同类型的细胞本身对生长天数没有显著不同的影响，但不同的试剂和试剂与细胞类型的组合却对生长天数有显著的影响。

## **第四步：检查模型假设**

我们需要检查残差是否近似正态分布，这是ANOVA的一个假设。

在实验室研究中，确保数据满足ANOVA的假设是非常重要的，因为这直接关系到你的结论是否可靠。如果残差分布显示出偏离正态分布的迹象，你可能需要转换数据或者使用非参数统计方法，这些方法不依赖于正态分布的假设。这样，你可以确保你的研究结论是建立在坚实的统计基础之上的。

### 如何检查残差的正态性？

**Q-Q图**（Quantile-Quantile图）：这种图形化方法可以直观地比较残差分布和标准正态分布。如果残差是正态分布的，那么Q-Q图上的点将近似地落在一条直线上。
```{r}
qqnorm(residuals(aov_result))
qqline(residuals(aov_result))
```
 **直方图**：你可以绘制残差的直方图，查看它是否形似钟形曲线。
```{r}
hist(residuals(aov_result))
```

**Shapiro-Wilk测试**：这是一个统计测试，用来判断一个样本是否来自于正态分布的总体。如果P值小于显著性水平（通常是0.05），则表示残差不遵循正态分布。Shapiro-Wilk测试适用于小样本数据（通常n<50），对于大样本数据，即使是微小的偏离正态性也可能导致显著的测试结果，因此对大样本数据（例如n>2000），使用这个测试的结果需要谨慎解读。对于较大的样本，你可能需要依赖于图形化方法（如Q-Q图）或其他正态性检验方法（如Kolmogorov-Smirnov测试）来评估数据的正态性。
```{r}
shapiro_res_test <- shapiro.test(residuals(aov_result))
shapiro_res_test
```
W: Shapiro-Wilk统计量的值是0.98798，这是一个接近1的值，意味着数据接近正态分布。
p-value: p-value是0.1298，这意味着没有足够的证据拒绝残差正态分布的原假设。换句话说，这个p-value高于0.05的常用显著性水平，我们不能断定残差不遵循正态分布。

这个Shapiro-Wilk测试的结果表明，ANOVA分析的残差满足正态分布的假设，因此，从正态性的角度看，使用ANOVA方法是合适的。

## ANOVA 小课堂

在使用ANOVA等统计测试时，我们通常假设数据满足一定的条件，以确保测试结果的有效性。对于ANOVA，一个重要的假设是数据的残差（实际观测值与模型预测值之差）近似正态分布。现在，让我们深入了解这个概念：

### 正态分布是什么？

正态分布，也称为高斯分布，是一个在统计学中非常重要的概率分布。它的图形表现为著名的钟形曲线，这个曲线是对称的，并且两端会无限接近于横轴但永远不会触及。在正态分布中，大部分的数据点会集中在平均值（中心）附近，而远离平均值的极端值较少。

### 为什么残差要近似正态分布？

ANOVA的一些关键数学性质假设数据来自近似正态分布的总体。如果残差分布不是正态的，那么ANOVA的结果可能不准确或具有误导性，因为：

1. 非正态分布的数据可能表明存在异常值或数据不均匀，这可能影响ANOVA的F值和P值的计算。
2. ANOVA的统计显著性测试依赖于残差的正态性；如果残差不是正态分布，P值可能不可靠。


## **第五步：Post hoc 测试**

如果ANOVA显示显著性，你可能需要进行post hoc测试来查看哪些组之间存在显著差异。

```{r}
# TukeyHSD进行多重比较
TukeyHSD(aov_result)
```

Tukey的多重比较测试是用来在ANOVA分析之后进行的，它帮助我们了解哪些组之间的差异是显著的。这里是一个简化的解释：

1. `diff` 列表示了两组之间的平均差异。
2. `lwr` 和 `upr` 分别表示差异的95%置信区间的下限和上限。如果这个区间不包含0，那么我们可以说这两组之间有显著差异。
3. `p adj` 是经过调整的p值，用来考虑进行多次比较时出现假阳性的风险。如果`p adj` 小于0.05，我们通常认为两组之间有显著差异。

### cell_type
- 细胞类型B和A之间的差异不显著（p adj = 0.8325703），因为置信区间包括了0。
- 细胞类型C和A之间的差异也不显著（p adj = 0.8885806），因为置信区间包括了0。
- 细胞类型C和B之间的差异也不显著（p adj = 0.9928783），因为置信区间包括了0。

### reagents_type
- 试剂类型Y和X之间的差异非常显著（p adj = 0），因为置信区间不包含0，而且差异很大。

### cell_type:reagents_type
- 当我们考虑细胞类型和试剂类型的组合时，差异变得复杂。我们看到，例如，细胞类型B在试剂X条件下与细胞类型A在试剂X条件下相比，存在显著差异（p adj = 1.8e-06）。
- 同样，其他组合比较，如C:X 与 A:X，A:Y 与 A:X 等，差异都是显著的（p adj 接近于0），意味着这些条件下的平均值差异非常显著。

简而言之，Tukey的测试告诉我们，在细胞类型上没有找到显著差异，但在试剂类型上以及细胞类型和试剂类型的组合上发现了显著差异。这可能意味着，尽管单独看细胞类型时没有差异，但当我们将细胞类型与不同试剂类型结合时，这些条件如何影响细胞的效果则有明显不同。

## **第六步：可视化结果**

```{r}
# 使用ggplot2绘图
library(ggplot2)
ggplot(cell_growth, aes(x = reagents_type, y = days, fill = cell_type)) +
  geom_boxplot() +
  facet_wrap(~ cell_type) +
  theme_minimal() +
  labs(title = "Cell Growth with Different Regents", x = "Reagents Type", y = "Days")
```

最后，我们可视化数据来直观显示差异。

# 线性回归

线性回归是用来预测一个变量（响应变量）与一个或多个其他变量（解释变量）之间关系的统计方法。

lm() 是 R 中进行线性回归的函数。函数 lm() 会输出一个模型，这个模型展示了变量间的线性关系。

研究细胞生长速率与培养基中添加的某种营养素的浓度之间的关系。你的目标是找出营养素浓度是否显著影响细胞生长，并确定它们之间的关系类型（是否是线性关系）。

实验步骤可能包括：

1. **准备实验**：
   - 准备一系列含有不同浓度的营养素的培养基。
   - 将相同数量的细胞接种到每个培养基中。

2. **收集数据**：
   - 记录每个培养基中细胞的生长速率（可以通过测量一定时间内的细胞数量增加来估计）。

3. **线性回归分析**：
   - 使用R进行线性回归分析，营养素浓度作为自变量（预测变量），细胞生长速率作为因变量（响应变量）。

```{r}
set.seed(2023) # 为了确保结果的可重复性

# 假设营养素浓度范围从0到10，我们有100个样本点
nutrient_concentration <- runif(100, min = 0, max = 10)

# 假设生长速率和营养素浓度有线性关系，但也加入一些随机噪声
# 例如：growth_rate = 2 * nutrient_concentration + error
growth_rate <- 2 * nutrient_concentration + rnorm(100, mean = 0, sd = 2)

# 创建数据框
experiment_data <- data.frame(
  nutrient_concentration = nutrient_concentration,
  growth_rate = growth_rate
)

experiment_data # 显示数据框

```

```{r}
model <- lm(growth_rate ~ nutrient_concentration, data = experiment_data)
```


```{r}
summary(model)
```

这段输出是来自R中`lm()`函数的线性模型摘要，它表示对实验数据进行的线性回归分析的结果。

1. **调用（Call）**:
   这部分只是告诉你进行线性回归分析时所用的公式。这里的公式是 `growth_rate ~ nutrient_concentration`，意味着你想用营养素浓度来预测生长速率。

2. **残差（Residuals）**:
   残差是实际观察到的生长速率与通过营养素浓度预测出来的生长速率之间的差异。
   - **最小值（Min）和最大值（Max）**: 残差中的最低点和最高点。
   - **第一四分位数（1Q）和第三四分位数（3Q）**: 残差的中间值，大约有一半的残差会比这个数小，一半会比这个数大。
   - **中位数（Median）**: 所有残差的中点值。

3. **系数（Coefficients）**:
   这部分告诉我们预测模型中的数学关系。
   - **(Intercept)**: 当营养素浓度为0时的预测生长速率。这里是0.91256。
   - **nutrient_concentration**: 这是营养素浓度的影响系数，可以理解为每增加一个单位的营养素浓度，生长速率平均增加1.85464个单位。

4. **标准误差（Std. Error）**:
   表示估计系数的准确性。数值越小，估计越精确。

5. **t值（t value）** 和 **p值（Pr(>|t|)）**:
   - 这两个值用来测试每个系数是否显著。如果p值很小（通常小于0.05），则我们认为该系数是统计显著的，对预测模型很重要。
   - 在这里，营养素浓度的p值非常小（<2e-16），这意味着我们非常确信营养素浓度和生长速率之间有关联。

6. **残差标准误差（Residual standard error）**:
   这是残差的一个度量，可以理解为预测值的平均误差。在这个例子中是1.977。

7. **多重R方（Multiple R-squared）** 和 **调整后的R方（Adjusted R-squared）**:
   - 这些值告诉我们模型的拟合优度，即模型对观察数据的解释程度。0.87非常高，说明模型解释了大部分的变异性。
   - 调整后的R方对自由度进行了调整，可以比较不同数量预测变量的模型。

8. **F统计量（F-statistic）** 和 它的 **p值**:
   - 这个F统计量用来测试模型中至少有一个预测变量是统计显著的。
   - 这个非常低的p值（< 2.2e-16）告诉我们，营养素浓度对生长速率有显著影响。

总的来说，这个线性模型表明营养素浓度是一个很好的生长速率预测因子，模型的拟合度很高。


### 绘制散点图和回归线
```{r}
ggplot(experiment_data, aes(x = nutrient_concentration, y = growth_rate)) +
  geom_point() +                                # 绘制散点
  geom_smooth(method = "lm", se = FALSE) +      # 绘制线性回归线，不包括置信区间
  labs(x = "营养素浓度", y = "细胞生长速率", title = "营养素浓度与细胞生长速率的关系") +
  theme_minimal()
```

如果p值小于你的显著性水平（通常为0.05），则可以认为营养素浓度与细胞生长速率之间存在显著的线性关系。而R平方值则告诉你模型拟合的好坏，即营养素浓度变化能解释细胞生长速率变化的比例。
