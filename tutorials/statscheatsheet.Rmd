---
title: "Statistics Cheat Sheet"
date: "`r Sys.Date()`"
author: "HJ. S."
output:
  rmdformats::downcute:
    code_folding: show
    self_contained: true
    thumbnails: false
    lightbox: true
pkgdown:
  as_is: true
---

# 基础统计学概念

## 常见的统计量

用于帮助我们理解数据的特点，可以得到数据集的一个很好的概述，了解数据的分布和中心趋势

1. **最小值 (Min)**：
   - 这是数据集中最小的数值。
   - 例如，在一个包含 2, 4, 7, 9 的数据集中，最小值是 2。

2. **下四分位数 (Quantile 1) 或 25th 百分位数**：
   - 也称为第一四分位数，它是将数据集分为四等分后的第一个切点。
   - 例如，在一个包含 1, 2, 3, 4, 5, 6, 7, 8 的数据集中，Q1 的值是 2.75 (25% 的数据小于或等于这个数值)。

3. **中位数 (Median) 或 Quantile 2**：
   - 中位数是将数据集从中间分开的值，一半的数据值位于中位数的左边，另一半位于右边。
   - 如果数据集的数量是奇数，则中位数就是中间的数；如果是偶数，则中位数是中间两个数的平均值。
   - 例如，在一个包含 3, 5, 7, 9 的数据集中，中位数是 6。

4. **平均数 (Mean)**：
   - 平均数是所有数据值的总和除以数据值的数量。
   - 例如，在一个包含 2, 3, 4, 5 的数据集中，平均数是 (2+3+4+5) / 4 = 3.5。

5. **上四分位数 (Quantile 3) 或 75th 百分位数**：
   - 也称为第三四分位数，它是将数据集分为四等分后的第三个切点。
   - 例如，在一个包含 1, 2, 3, 4, 5, 6, 7, 8 的数据集中，Q3 的值是 5.25 (75% 的数据小于或等于这个数值)。

6. **最大值 (Max)**：
   - 这是数据集中最大的数值。
   - 例如，在一个包含 2, 4, 7, 9 的数据集中，最大值是 9。

7. **频数 (Frequency)**:
   - 例如，在一个数据集{1, 2, 2, 3, 3, 3, 4}中，数字3的频数是3，因为它出现了三次。

8. **频率 (Relative Frequency)**:
   - 在同一个数据集{1, 2, 2, 3, 3, 3, 4}中，数字3的频率是3/7 ≈ 0.43，因为它出现了三次，总的数据点数量是7。

9. **标准差 (Standard Deviation, SD)**:
   - 在数据集{2, 4, 4, 4, 5, 5, 7, 9}中，标准差是2，这意味着数据点离平均值的平均距离是2。

10. **方差 (Variance)**:
    - 在同一个数据集{2, 4, 4, 4, 5, 5, 7, 9}中，方差是4，因为标准差的平方是2^2 = 4。

11. **范围 (Range)**:
    - 在数据集{2, 4, 7, 9}中，范围是7，因为最大值9减最小值2等于7。

12. **众数 (Mode)**:
    - 在数据集{1, 2, 2, 3, 3, 3, 4}中，众数是3，因为3出现的次数最多。

13. **偏度 (Skewness)**:
    - 如果我们有一个数据集{1, 2, 2, 3, 3, 3, 4}，它的偏度是0，因为数据是对称分布的。

14. **峰度 (Kurtosis)**:
    - 在一个尖峰分布的数据集中，峰度会高于正态分布的峰度。例如，数据集{1, 1, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4}的峰度较高，因为数据集的尾部较重。

15. **百分位数 (Percentile)**:
    - 在数据集{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}中，第25个百分位数是3.25，因为25%的数据小于或等于这个值。

16. **相关系数 (Correlation Coefficient)**:
    - 如果我们有两组数据，比如{1, 2, 3, 4, 5}和{2, 4, 6, 8, 10}，它们之间的相关系数是1，因为它们之间存在完全的正线性关系。

17. **回归分析 (Regression Analysis)**:
    - 例如，我们想预测房价基于房子的大小。通过回归分析，我们可以得到一个方程，用来预测基于房子大小的房价。

18. **样本 (Sample)**:
    - 如果我们有一个包含1000个人的大型社区，我们可能只从中抽取100个人来研究他们的收入水平，这100个人就是一个样本。

19. **总体 (Population)**:
    - 在上述例子中，这个社区的所有1000个人就是总体。

20. **极值 (Outlier)**:
    - 在数据集中明显偏离其他观测点的数值

# 概率理论简介

**定义与学术名称（中英文）**:
1. **概率（Probability）**: 概率是衡量某个事件发生可能性的数值。它的值介于0和1之间，0表示事件不可能发生，1表示事件必然发生。

2. **随机变量（Random Variable）**: 随机变量是一种数值，其值取决于某个随机过程的结果。例如，掷骰子的结果可以是1到6的任意整数。

3. **概率分布（Probability Distribution）**: 概率分布描述了随机变量取每个可能值的概率。常见的概率分布包括二项分布、正态分布等。

4. **期望值（Expected Value）**: 期望值是随机变量在多次试验中平均可能达到的值。

5. **方差（Variance）**: 方差衡量随机变量取值的分散程度，即其分布的广泛性。

### 听故事理解概率理论


在霍格沃茨，有一位名叫艾米的学生收到了一个神奇的糖果袋，袋子里有五种颜色的糖果：红色、蓝色、绿色、黄色和紫色。艾米想知道每次随机抽取一颗糖果时得到每种颜色的概率。

她记录了每种颜色糖果的数量：红色10颗，蓝色15颗，绿色5颗，黄色20颗，紫色10颗。总共有60颗糖果。

1. **计算概率**:
   - 抽到红色糖果的概率是10/60。
   - 抽到蓝色糖果的概率是15/60。
   - 以此类推。

2. **期望值**:
   - 如果每种颜色的糖果代表不同的分数（红色1分，蓝色2分等），艾米可以计算她期望得到的平均分数。

3. **多次抽取**:
   - 艾米每天都抽取一颗糖果，记录下来。随着时间的推移，她会发现实际结果越来越接近她最初计算的概率。

通过这个故事，我们可以看到概率是如何在实际生活中被应用的，以及如何通过观察和记录来验证概率理论。这个简单的例子展示了概率的基本概念，并帮助我们理解概率在预测未来事件中的作用。



# 统计学术语

简单来说，只要 p<0.05， 我们就可以说，这个结论不是随即发生的，是受到一定因素影响的

## 统计学显著 statitical significant
统计学显著性是一个衡量结果不太可能是偶然发生的标准。在统计假设检验中，我们通常设置一个阈值（显著性水平），如0.05或5%，来决定一个统计结果是否显著。如果得到的p值小于这个阈值，我们就说结果在统计上是显著的。

以下是一些与统计学显著性相关的关键点：

### 假设检验
- **Null Hypothesis (H0)**: 一个基准假设，通常是表明没有效果或差异的假设，如两个样本的均值之间没有差异。例如，在药物测试中，零假设可能是新药物与安慰剂没有差异。

- **Alternative Hypothesis (H1)**: 这是与零假设对立的假设，即存在某种效果或差异，通常是研究者希望证实的假设。继续药物测试的例子，备择假设可能是新药物比安慰剂更有效。

### P值
- **P值**: 给出了在零假设为真的情况下，观察到的数据或更极端数据出现的概率。一个低的p值（通常小于0.05）表明在零假设下这样的数据是不太可能的，因此我们拒绝零假设。

### 显著性水平（α）
- **显著性水平**: 是在实验之前选择的一个阈值，它定义了拒绝零假设的标准。如果p值小于显著性水平（例如，α=0.05），我们认为结果在统计上显著。

### 类型 I 和 类型 II 错误
- **类型 I 错误（错误的拒绝真正的零假设）**: 当零假设实际上是真的时我们却拒绝了它，犯了类型 I 错误。显著性水平就是犯这种错误的概率。当零假设实际上是错误的，但是没有被拒绝时发生的错误。这相当于假阳性，比如错误地认为无效药物是有效的。

- **类型 II 错误（错误地接受了一个假的零假设）**: 当零假设是假的但是我们没有拒绝它时，我们犯了类型 II 错误。这个错误的概率用β表示。当零假设实际上是错误的，但是没有被拒绝时发生的错误。这相当于假阴性，比如没有识别出有效药物的效果。



### 听故事学统计 

让我们通过一个简单的故事来理解统计学中的显著性，以及为什么通常使用 \( p < 0.05 \) 作为显著性水平的标准。

故事发生在一个小村庄，村里有一个流言说，喝了村边小河的水可以提高记忆力。为了验证这个说法，村里的科学家小明决定进行一个实验。

小明选择了100名村民，随机分为两组，每组50人。一组喝河水，另一组喝普通水。一个月后，小明对两组人进行记忆力测试。测试结果显示，喝河水的那组人的平均记忆力得分略高于另一组。

但小明知道，仅凭观察到的差异不能就认为河水真的能提高记忆力。这里就涉及到了统计学的显著性测试。小明计算了一个p值，这个p值表示如果河水真的不影响记忆力，那么观察到的差异或更大差异发生的概率。

如果p值很小，比如小于0.05，这意味着如果河水真的不影响记忆力，那么观察到现有差异的概率只有5%。这是很小的概率，因此小明可以相对有信心地说，这个差异不是偶然发生的，河水可能真的有提高记忆力的效果。

相反，如果p值大于0.05，这意味着即使河水不影响记忆力，观察到现有差异的概率也不算小。在这种情况下，小明不能肯定河水确实有作用，因为观察到的差异可能仅仅是偶然发生的。

这个故事说明了统计显著性的概念，以及为什么p值小于0.05常被用作决定结果是否显著的标准。这个标准帮助研究者区分观察到的效果是真实的还是偶然发生的。

在一个古老的村庄里，有一个传说，村庄中心的古井水具有治愈疾病的神奇功效。村里的治疗师小李对此表示怀疑，并决定进行实验来验证这个说法。

小李的实验包括两组人群：一组喝古井水，另一组喝普通井水。他的**零假设**是古井水与普通井水在治疗效果上没有差异。相对的，他的**备择假设**是古井水比普通井水有更好的治疗效果。

几周后，小李观察到喝古井水的人群似乎恢复得更快，于是他拒绝了零假设，认为古井水确实有特殊的治愈效果。但这里有两种可能的错误：

- **类型一错误**：如果实际上古井水并无特殊效果，小李的结论就是错误的。这就像他错误地认为古井水有效，实际上可能只是因为其他因素，如心理作用或自然恢复。
  
- **类型二错误**：如果古井水确实有治愈效果，但小李没有观察到显著差异，继续相信零假设，那么他就忽略了古井水的真实效果。

在统计学中，我们通过显著性测试（如 p 值）来决定是否拒绝零假设，同时也意识到可能犯下类型一或类型二错误的风险。这就是为什么统计结论通常是说“我们发现了证据支持……”而不是“我们证明了……”，因为总存在一些不确定性。

### 统计力量
- **统计力量**: 是正确拒绝错误零假设的能力，即发现实际存在的效果的能力。统计力量与样本大小、效应量和显著性水平有关。

总结一下，统计学显著性是我们用来确定观察到的数据模式是否不太可能仅仅是随机变异的一种方法。通过设定显著性水平，并计算得到的统计量的p值，我们能够决定是否拒绝零假设。如果拒绝了零假设，我们通常会声称发现了统计学上显著的效果。这是一种通过数据来支持或反对某个科学假设的方法。

## 置信区间

置信区间是一个来自于统计学的概念，它提供了对未知参数（比如平均数、比例、差异等）可能值的一个区间估计。在实际应用中，这个区间表示了，在一定的置信水平（常见的如95%）下，参数的真实值有很大概率落在这个区间内。这是基于抽样分布和概率的概念，意味着如果我们重复抽样和计算置信区间很多次，那么有95%的这些区间将包含真实的参数值。

当我们在Tukey的多重比较结果中看到一个置信区间时，它代表了：

- `lwr`：置信区间的下限（Lower bound）
- `upr`：置信区间的上限（Upper bound）

如果置信区间的两个边界值`lwr`和`upr`都是正数，或者都是负数，那么我们可以说这个置信区间不包括0，这通常意味着差异是统计学上显著的。相反，如果置信区间从负数跨越到正数（即`lwr`是负的，`upr`是正的），这个区间就包含了0，通常表明差异不是统计学上显著的。

例如，假设一个置信区间是(-1.79, 1.08)：

- 这个置信区间的下限是-1.79，上限是1.08。
- 因为这个区间包括了从负数到正数的值，所以它包含了0。
- 这表示我们不能拒绝两组之间没有差异的假设。

在实际应用中，置信区间的宽度也提供了一定的信息，更宽的置信区间意味着更大的不确定性。置信区间的宽度受样本大小、变异性以及置信水平的影响。更大的样本、更低的变异性或更低的置信水平（如90%）通常会导致更窄的置信区间，表示估计更精确。



# ANOVA 统计分析

我们将假设我们正在研究三种不同种类的细胞在不同试剂处理下的生长效果。目标是判断试剂类型是否对细胞生长有显著影响。

## **第一步：收集数据**

首先，你会收集数据。比如你有三种细胞（A、B、C），并且有两种试剂类型（X和Y）。你测量了使用不同试剂后细胞的生长速度。数据可能是这样收集的：

- Cell A with Reagents X
- Cell A with Reagents Y
- Cell B with Reagents X
- Cell B with Reagents Y
- Cell C with Reagents X
- Cell C with Reagents Y

每个组合收集30个数据点。

## **第二步：整理数据**

将数据整理成一个`data.frame`对象，例如:

```{r}
# 假设的数据
set.seed(123) # 确保结果的可重复性
cell_growth <- data.frame(
  cell_type = factor(rep(c("A", "B", "C"), each = 60)),
  reagents_type = factor(rep(c("X", "Y"), each = 30)),
  days = c(rnorm(30, mean = 35, sd = 3.5), 
             rnorm(30, mean = 40, sd = 3.5), 
             rnorm(30, mean = 30, sd = 3.5), 
             rnorm(30, mean = 45, sd = 3.5), 
             rnorm(30, mean = 25, sd = 3.5), 
             rnorm(30, mean = 50, sd = 3.5))
)
head(cell_growth)
```


## **第三步：进行ANOVA分析**

我们使用ANOVA来看看试剂类型是否显著影响细胞生长速度。

```{r}
# ANOVA
aov_result <- aov(days ~ cell_type * reagents_type, data = cell_growth)
summary(aov_result)
```

### 如何分析这个模型结果：

想象你是一位生物学家，正在研究不同类型的细胞（`cell_type`）和不同试剂（`reagents_type`）对细胞生长天数的影响。你设计了一个实验来评估：

1. 不同细胞类型是否影响细胞生长天数。
2. 不同试剂是否影响细胞生长天数。
3. 细胞类型和试剂是否相互作用影响细胞生长天数。

你的实验结果包括以下几个方面：

- **Df（自由度）**：这是指你在分析数据时自由选择数据点的能力。例如，如果你有三种细胞类型，自由度就是2（一旦你知道了两种细胞的生长情况，第三种就不再自由）。自由度。它是指在计算某个统计量时，能够自由变动的值的个数。这里，cell_type有2个自由度（通常是类别数减1），reagents_type有1个自由度，它们的交互作用 cell_type:reagents_type有2个自由度，最后Residuals（残差，也就是无法由模型解释的变异）有174个自由度。

- **Sum Sq（总平方和）**：这是所有数据点偏离整体平均值的平方和，它衡量的是因变量（这里是细胞生长天数）的总变异量。在你的实验中，总平方和越大，表示变异越大，相应因素的影响可能就越显著。它表示由该因子引起的变异量总和。在这里，cell_type引起的变异很小，只有4，而reagents_type引起的变异非常大，为10837。

- **Mean Sq（均方）**：这是总平方和除以相应的自由度得到的，它代表了每个因素引起的平均变异大小。它是和平方和除以对应的自由度，反映了每个因子每个自由度上的平均变异量。比如reagents_type的均方是10837，这意味着每一个reagents_type类别带来的平均变异量是10837。

- **F value**：这是用来比较模型中的均方与残差均方的比率。如果这个比率足够大，说明模型中的对应因素有统计学意义。F值是均方之间的比率。它用于检验我们的组间是否有显著差异。在这里，reagents_type的F值是974.933，而cell_type:reagents_type的交互作用的F值是141.159，这两个都相对较高，表明它们各自和共同都对结果有显著影响。

- **Pr(>F)（P值）**：这是你观测到的F值或更极端情况出现的概率。一个低P值（通常小于0.05）表明结果具有统计学意义，即非随机差异的可能性很高。这个是P值，用来告诉我们观察到的数据在没有任何效应的情况下（即零假设），出现的概率。如果这个值很小，它表明这种情况出现的可能性很低，我们就可以拒绝零假设。在这个输出中，reagents_type和cell_type:reagents_type的P值都远远小于0.001（标记为***），这表示它们的影响是非常显著的。而cell_type的P值为0.83，表明它并没有显著影响

### 根据你的实验结果：

- `cell_type`的P值为0.83，表明不同的细胞类型对细胞生长天数的影响不显著，细胞类型的变化并不会导致生长天数的显著变化。

- `reagents_type`的P值非常低（<0.001），这意味着不同的试剂显著影响了细胞的生长天数。换句话说，试剂的种类是一个影响细胞生长天数的重要因素。

- `cell_type`和`reagents_type`的交互作用也有非常低的P值（<0.001），表示细胞类型和试剂的组合对细胞生长天数有显著的联合影响。也就是说，某些试剂可能对某些细胞类型的生长影响特别大。

综上所述，你的实验表明，尽管不同类型的细胞本身对生长天数没有显著不同的影响，但不同的试剂和试剂与细胞类型的组合却对生长天数有显著的影响。

## **第四步：检查模型假设**

我们需要检查残差是否近似正态分布，这是ANOVA的一个假设。

在实验室研究中，确保数据满足ANOVA的假设是非常重要的，因为这直接关系到你的结论是否可靠。如果残差分布显示出偏离正态分布的迹象，你可能需要转换数据或者使用非参数统计方法，这些方法不依赖于正态分布的假设。这样，你可以确保你的研究结论是建立在坚实的统计基础之上的。

### 如何检查残差的正态性？

**Q-Q图**（Quantile-Quantile图）：这种图形化方法可以直观地比较残差分布和标准正态分布。如果残差是正态分布的，那么Q-Q图上的点将近似地落在一条直线上。
```{r}
qqnorm(residuals(aov_result))
qqline(residuals(aov_result))
```
 **直方图**：你可以绘制残差的直方图，查看它是否形似钟形曲线。
```{r}
hist(residuals(aov_result))
```

**Shapiro-Wilk测试**：这是一个统计测试，用来判断一个样本是否来自于正态分布的总体。如果P值小于显著性水平（通常是0.05），则表示残差不遵循正态分布。Shapiro-Wilk测试适用于小样本数据（通常n<50），对于大样本数据，即使是微小的偏离正态性也可能导致显著的测试结果，因此对大样本数据（例如n>2000），使用这个测试的结果需要谨慎解读。对于较大的样本，你可能需要依赖于图形化方法（如Q-Q图）或其他正态性检验方法（如Kolmogorov-Smirnov测试）来评估数据的正态性。
```{r}
shapiro_res_test <- shapiro.test(residuals(aov_result))
shapiro_res_test
```
W: Shapiro-Wilk统计量的值是0.98798，这是一个接近1的值，意味着数据接近正态分布。
p-value: p-value是0.1298，这意味着没有足够的证据拒绝残差正态分布的原假设。换句话说，这个p-value高于0.05的常用显著性水平，我们不能断定残差不遵循正态分布。

这个Shapiro-Wilk测试的结果表明，ANOVA分析的残差满足正态分布的假设，因此，从正态性的角度看，使用ANOVA方法是合适的。

## ANOVA 小课堂

在使用ANOVA等统计测试时，我们通常假设数据满足一定的条件，以确保测试结果的有效性。对于ANOVA，一个重要的假设是数据的残差（实际观测值与模型预测值之差）近似正态分布。现在，让我们深入了解这个概念：

### 正态分布是什么？

正态分布，也称为高斯分布，是一个在统计学中非常重要的概率分布。它的图形表现为著名的钟形曲线，这个曲线是对称的，并且两端会无限接近于横轴但永远不会触及。在正态分布中，大部分的数据点会集中在平均值（中心）附近，而远离平均值的极端值较少。

### 为什么残差要近似正态分布？

ANOVA的一些关键数学性质假设数据来自近似正态分布的总体。如果残差分布不是正态的，那么ANOVA的结果可能不准确或具有误导性，因为：

1. 非正态分布的数据可能表明存在异常值或数据不均匀，这可能影响ANOVA的F值和P值的计算。
2. ANOVA的统计显著性测试依赖于残差的正态性；如果残差不是正态分布，P值可能不可靠。


## **第五步：Post hoc 测试**

如果ANOVA显示显著性，你可能需要进行post hoc测试来查看哪些组之间存在显著差异。

```{r}
# TukeyHSD进行多重比较
TukeyHSD(aov_result)
```

Tukey的多重比较测试是用来在ANOVA分析之后进行的，它帮助我们了解哪些组之间的差异是显著的。这里是一个简化的解释：

1. `diff` 列表示了两组之间的平均差异。
2. `lwr` 和 `upr` 分别表示差异的95%置信区间的下限和上限。如果这个区间不包含0，那么我们可以说这两组之间有显著差异。
3. `p adj` 是经过调整的p值，用来考虑进行多次比较时出现假阳性的风险。如果`p adj` 小于0.05，我们通常认为两组之间有显著差异。

### cell_type
- 细胞类型B和A之间的差异不显著（p adj = 0.8325703），因为置信区间包括了0。
- 细胞类型C和A之间的差异也不显著（p adj = 0.8885806），因为置信区间包括了0。
- 细胞类型C和B之间的差异也不显著（p adj = 0.9928783），因为置信区间包括了0。

### reagents_type
- 试剂类型Y和X之间的差异非常显著（p adj = 0），因为置信区间不包含0，而且差异很大。

### cell_type:reagents_type
- 当我们考虑细胞类型和试剂类型的组合时，差异变得复杂。我们看到，例如，细胞类型B在试剂X条件下与细胞类型A在试剂X条件下相比，存在显著差异（p adj = 1.8e-06）。
- 同样，其他组合比较，如C:X 与 A:X，A:Y 与 A:X 等，差异都是显著的（p adj 接近于0），意味着这些条件下的平均值差异非常显著。

简而言之，Tukey的测试告诉我们，在细胞类型上没有找到显著差异，但在试剂类型上以及细胞类型和试剂类型的组合上发现了显著差异。这可能意味着，尽管单独看细胞类型时没有差异，但当我们将细胞类型与不同试剂类型结合时，这些条件如何影响细胞的效果则有明显不同。

## **第六步：可视化结果**

```{r}
# 使用ggplot2绘图
library(ggplot2)
ggplot(cell_growth, aes(x = reagents_type, y = days, fill = cell_type)) +
  geom_boxplot() +
  facet_wrap(~ cell_type) +
  theme_minimal() +
  labs(title = "Cell Growth with Different Regents", x = "Reagents Type", y = "Days")
```

最后，我们可视化数据来直观显示差异。

# 线性回归

线性回归是用来预测一个变量（响应变量）与一个或多个其他变量（解释变量）之间关系的统计方法。

lm() 是 R 中进行线性回归的函数。函数 lm() 会输出一个模型，这个模型展示了变量间的线性关系。

研究细胞生长速率与培养基中添加的某种营养素的浓度之间的关系。你的目标是找出营养素浓度是否显著影响细胞生长，并确定它们之间的关系类型（是否是线性关系）。

实验步骤可能包括：

1. **准备实验**：
   - 准备一系列含有不同浓度的营养素的培养基。
   - 将相同数量的细胞接种到每个培养基中。

2. **收集数据**：
   - 记录每个培养基中细胞的生长速率（可以通过测量一定时间内的细胞数量增加来估计）。

3. **线性回归分析**：
   - 使用R进行线性回归分析，营养素浓度作为自变量（预测变量），细胞生长速率作为因变量（响应变量）。

```{r}
set.seed(2023) # 为了确保结果的可重复性

# 假设营养素浓度范围从0到10，我们有100个样本点
nutrient_concentration <- runif(100, min = 0, max = 10)

# 假设生长速率和营养素浓度有线性关系，但也加入一些随机噪声
# 例如：growth_rate = 2 * nutrient_concentration + error
growth_rate <- 2 * nutrient_concentration + rnorm(100, mean = 0, sd = 2)

# 创建数据框
experiment_data <- data.frame(
  nutrient_concentration = nutrient_concentration,
  growth_rate = growth_rate
)

head(experiment_data,n=2) # 显示数据框

```

```{r}
model <- lm(growth_rate ~ nutrient_concentration, data = experiment_data)
```


```{r}
summary(model)
```

这段输出是来自R中`lm()`函数的线性模型摘要，它表示对实验数据进行的线性回归分析的结果。

1. **调用（Call）**:
   这部分只是告诉你进行线性回归分析时所用的公式。这里的公式是 `growth_rate ~ nutrient_concentration`，意味着你想用营养素浓度来预测生长速率。

2. **残差（Residuals）**:
   残差是实际观察到的生长速率与通过营养素浓度预测出来的生长速率之间的差异。
   - **最小值（Min）和最大值（Max）**: 残差中的最低点和最高点。
   - **第一四分位数（1Q）和第三四分位数（3Q）**: 残差的中间值，大约有一半的残差会比这个数小，一半会比这个数大。
   - **中位数（Median）**: 所有残差的中点值。

3. **系数（Coefficients）**:
   这部分告诉我们预测模型中的数学关系。
   - **(Intercept)**: 当营养素浓度为0时的预测生长速率。这里是0.91256。
   - **nutrient_concentration**: 这是营养素浓度的影响系数，可以理解为每增加一个单位的营养素浓度，生长速率平均增加1.85464个单位。

4. **标准误差（Std. Error）**:
   表示估计系数的准确性。数值越小，估计越精确。

5. **t值（t value）** 和 **p值（Pr(>|t|)）**:
   - 这两个值用来测试每个系数是否显著。如果p值很小（通常小于0.05），则我们认为该系数是统计显著的，对预测模型很重要。
   - 在这里，营养素浓度的p值非常小（<2e-16），这意味着我们非常确信营养素浓度和生长速率之间有关联。

6. **残差标准误差（Residual standard error）**:
   这是残差的一个度量，可以理解为预测值的平均误差。在这个例子中是1.977。

7. **多重R方（Multiple R-squared）** 和 **调整后的R方（Adjusted R-squared）**:
   - 这些值告诉我们模型的拟合优度，即模型对观察数据的解释程度。0.87非常高，说明模型解释了大部分的变异性。
   - 调整后的R方对自由度进行了调整，可以比较不同数量预测变量的模型。

8. **F统计量（F-statistic）** 和 它的 **p值**:
   - 这个F统计量用来测试模型中至少有一个预测变量是统计显著的。
   - 这个非常低的p值（< 2.2e-16）告诉我们，营养素浓度对生长速率有显著影响。

总的来说，这个线性模型表明营养素浓度是一个很好的生长速率预测因子，模型的拟合度很高。


### 绘制散点图和回归线
```{r}
ggplot(experiment_data, aes(x = nutrient_concentration, y = growth_rate)) +
  geom_point() +                                # 绘制散点
  geom_smooth(method = "lm", se = FALSE) +      # 绘制线性回归线，不包括置信区间
  labs(x = "营养素浓度", y = "细胞生长速率", title = "营养素浓度与细胞生长速率的关系") +
  theme_minimal()
```

如果p值小于你的显著性水平（通常为0.05），则可以认为营养素浓度与细胞生长速率之间存在显著的线性关系。而R平方值则告诉你模型拟合的好坏，即营养素浓度变化能解释细胞生长速率变化的比例。


# 结构方程模型 (SEM) 

结构方程模型（SEM）是一种复杂的统计分析方法，用于研究变量之间的关系。它可以同时考虑多个因变量和自变量，还可以包括潜在变量（即无法直接观测的变量，比如智力、满意度等）。结构方程模型能够同时进行多重回归分析、路径分析以及因子分析。

举一个简单的例子来说明：

假设我们想研究工作满意度（这是一个潜在变量，因为它无法直接测量）如何影响员工的离职率。我们可以通过问卷调查来测量工作满意度的几个方面，如薪资满意度、工作环境、同事关系等。这些具体可测量的变量称为观测变量。

在结构方程模型中，我们首先使用因子分析将薪资满意度、工作环境、同事关系等观测变量组合成一个潜在变量“工作满意度”。然后，我们使用路径分析来研究这个潜在变量“工作满意度”与另一个观测变量“离职率”的关系。

在这个模型中，我们可以同时分析多个因素如何影响工作满意度，以及工作满意度又是如何影响离职率的。这样，结构方程模型帮助我们更全面地理解了工作满意度与离职率之间的复杂关系。

结构方程模型的优点在于它能够处理复杂的变量关系，包括多个因变量和潜在变量，这在传统的统计方法中往往难以做到。不过，它也需要较高的统计知识和对数据的理解。


RMSEA、TLI和CFI是在结构方程模型（SEM）中常用的术语。结构方程模型是一种统计技术，用于测试多个变量之间的关系。这些指标用于评估模型的拟合度，即假设的模型代表数据的程度。下面我用更通俗的语言解释这三个术语：

1. **RMSEA（均方根误差近似值 Root Mean Square Error of Approximation）**：这是衡量模型拟合数据的好坏的一个指标。RMSEA的值在0到1之间，值越低表示拟合度越好。通常情况下，小于0.05的值被认为是很好的拟合，而0.08以下的值可以被接受。

2. **TLI（塔克-刘易斯指数 Tucker-Lewis Index）**：

这个指数是通过比较目标模型的卡方值与无关系模型（即变量之间没有关系的模型）的卡方值来评估模型拟合度的。TLI的值理论上在0到1之间，但有时也会超过1。接近1的值表示拟合度好。通常，大于0.95的值表示模型拟合得很好。

3. **CFI（比较拟合指数 Comparative Fit Index）**：

CFI类似于TLI，也是通过比较目标模型与无关系模型的拟合度来评估的，但它考虑到了样本大小。CFI的值也是在0到1之间，越接近1表示拟合度越好。0.95或更高的CFI值通常被认为是好的拟合度。

4. **SRMR（Standardized Root Mean Square Residual** :

是一种衡量结构方程模型（SEM）拟合度的指标。它主要用于评估模型残差的大小，可以理解为模型预测值与观测值之间差异的标准化平均值。以下是关于SRMR的一些关键点：

1. **含义**：
   - SRMR是模型残差（即误差）的标准化均方根。它量化了模型中各观测变量间的协方差（或相关性）与数据中相应协方差（或相关性）之间的差异。
   - 一个低的SRMR值表明模型与数据的残差较小，即模型对数据的拟合度较好。

2. **理想值**：
   - 通常，SRMR值越小越好。一般认为，SRMR值小于0.08表示模型拟合良好。
   - 有时也会使用更严格的标准，如小于0.05。

3. **与其他拟合指标的关系**：
   - SRMR是一种绝对拟合指标，与相对拟合指标（如CFI - Comparative Fit Index，TLI - Tucker-Lewis Index）和基于惩罚的拟合指标（如AIC - Akaike Information Criterion，BIC - Bayesian Information Criterion）不同。
   - SRMR与这些其他拟合指标一起使用，可以提供模型拟合度的全面视图。

4. **使用注意事项**：
   - 虽然SRMR是一个有用的指标，但它不应该单独用来评估模型的拟合度。最好结合其他指标一起使用，如CFI、TLI和RMSEA。
   - 在解释SRMR时，需要考虑模型的复杂性、样本大小以及数据的特性。

总的来说，SRMR提供了一个量化模型预测值与观测值之间差异大小的指标，是评价模型拟合度的重要工具之一。


这些指标用于全面评估提出的模型与数据的拟合程度。由于每个指标都有其局限性，且可以从不同角度反映模型拟合情况，因此使用多个指标是重要的。此外，这些指标的解释应结合研究的上下文，并与其他标准（如理论和以往研究）一起使用，而不应作为判断模型可接受性的唯一标准。